{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Musical Data Analysis\n",
    "\n",
    "Music is a form of art that is ubiquitous and has a rich history. Different composers have created music with their unique styles and compositions. However, identifying the composer of a particular piece of music can be a challenging task, especially for novice musicians or listeners. The proposed project aims to use deep learning techniques to identify the composer of a given piece of music accurately.\n",
    "\n",
    "### Objective\n",
    "The primary objective of this project is to develop a deep learning model that can predict the composer of a given musical score accurately. The project aims to accomplish this objective by using two deep learning techniques: Long Short-Term Memory (LSTM) and Convolutional Neural Network (CNN).\n",
    "\n",
    "### Data set\n",
    "\n",
    "The project will use a dataset consisting of musical scores from various composers. The dataset is downloaded from Kaggle web store https://www.kaggle.com/datasets/blanderbuss/midi-classic-music?resource=download\n",
    "\n",
    "The dataset contains the midi files of compositions from well-known classical composers like Bach, Beethoven, Chopin, and Mozart. The dataset should be labeled with the name of the composer for each score.\n",
    "\n",
    "1-Bach\n",
    "2-Beethoven\n",
    "3-Chopin\n",
    "4-Mozart\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection And Pre-processing\n",
    "\n",
    "The data is downloaded from the Kaggle webstore. It has multiple MIDI files from multiple classical composers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method to collect MID files for each top folder and subfolders\n",
    "\n",
    "We are considering only Bach, Beethoven, Chopin and Mozart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "925\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def collect_midi_files(root_folder):\n",
    "    # Use a set to store unique absolute paths\n",
    "    unique_files = set()\n",
    "    midi_files = []\n",
    "    \n",
    "    # Use glob to find all .mid files in root_folder and subfolders\n",
    "    relative_paths = glob.glob(os.path.join(root_folder, '**', '*.mid'), recursive=True)\n",
    "    \n",
    "    for relative_path in relative_paths:\n",
    "        absolute_path = os.path.abspath(relative_path)\n",
    "        # Check if the absolute path is already in the set\n",
    "        if absolute_path not in unique_files:\n",
    "            unique_files.add(absolute_path)\n",
    "            midi_files.append(absolute_path)\n",
    "    \n",
    "    return midi_files\n",
    "\n",
    "# Define the root folder\n",
    "root_folder = '/Users/manikanr/Downloads/archive/midiclassics/Bach'\n",
    "\n",
    "# Collect all unique .mid files with absolute paths\n",
    "midi_files = collect_midi_files(root_folder)\n",
    "print(len(midi_files))\n",
    "\n",
    "# Print the list of .mid files with absolute paths\n",
    "#for midi_file in midi_files:\n",
    "#    print(midi_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect Bach MID files under Bach folder and sub-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of mid files under Bach folder and subfolders are 925\n"
     ]
    }
   ],
   "source": [
    "# Define the root folder\n",
    "root_folder = '/Users/manikanr/Downloads/archive/midiclassics/Bach'\n",
    "\n",
    "# Collect all unique .mid files with absolute paths\n",
    "bach_midi_files = collect_midi_files(root_folder)\n",
    "print(\"The number of mid files under Bach folder and subfolders are {}\".format(len(bach_midi_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect Beethoven MID files under Beethoven folder and sub-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of mid files under Beethoven folder and subfolders are 212\n"
     ]
    }
   ],
   "source": [
    "# Define the root folder\n",
    "root_folder = '/Users/manikanr/Downloads/archive/midiclassics/Beethoven'\n",
    "\n",
    "# Collect all unique .mid files with absolute paths\n",
    "beethoven_midi_files = collect_midi_files(root_folder)\n",
    "print(\"The number of mid files under Beethoven folder and subfolders are {}\".format(len(beethoven_midi_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect Chopin MID files under Chopin folder and sub-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of mid files under Chopin folder and subfolders are 136\n"
     ]
    }
   ],
   "source": [
    "# Define the root folder\n",
    "root_folder = '/Users/manikanr/Downloads/archive/midiclassics/Chopin'\n",
    "\n",
    "# Collect all unique .mid files with absolute paths\n",
    "chopin_midi_files = collect_midi_files(root_folder)\n",
    "print(\"The number of mid files under Chopin folder and subfolders are {}\".format(len(chopin_midi_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect Mozart MID files under Mozart folder and sub-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of mid files under Mozart folder and subfolders are 257\n"
     ]
    }
   ],
   "source": [
    "# Define the root folder\n",
    "root_folder = '/Users/manikanr/Downloads/archive/midiclassics/Mozart'\n",
    "\n",
    "# Collect all unique .mid files with absolute paths\n",
    "mozart_midi_files = collect_midi_files(root_folder)\n",
    "print(\"The number of mid files under Mozart folder and subfolders are {}\".format(len(mozart_midi_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avoid overfitting for Bach\n",
    "\n",
    "Bach has 957 files and Chopin has only 136. We don't want tthe model to be overfit for Bach during training. So, the base of 136 MID files will be used to fit our models for all 4 composers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Python Music Libraries to use for Feature Extraction\n",
    "\n",
    "There are many python music libraries available to work with MID files. But, the below 2 libraries stands out for classical music analysis.\n",
    "\n",
    "1. Music 21 - Music21 provides robust feature extraction tools to split notes, chords, tempo, key, time signatures and Rhythmic patterns.\n",
    "2. PrettyMIDI - Equally good tool but doesn't provide direct method to get Chords.\n",
    "\n",
    "Due to its robust features and tools, the Music21 is used in our project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Music21 for Feature Extraction\n",
    "\n",
    "Music21 has libraries like converter which converts entire MID file into a stream of musical score. This stream has data about notes, chords, tempo, key and time signatures and rhythmic patterns. the notes, chords, tempo etc can be extracted from this stream as features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method to extract notes, chords, tempo, key, time signatures and rhythmic patterns.\n",
    "\n",
    "Music21 has libraries for splitting MID files with above data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Music21 on single MID file to check on features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter, note, chord, metadata, tempo, key, meter\n",
    "\n",
    "# Load the MIDI file\n",
    "score = converter.parse('/Users/manikanr/Downloads/archive/midiclassics/Bach/Bwv0525 Sonate en trio n1.mid')\n",
    "\n",
    "# Extract Notes\n",
    "notes = []\n",
    "chords = []\n",
    "tempos = []\n",
    "rhythmic_patterns = []\n",
    "time_signatures = []\n",
    "    \n",
    "# Extract Notes, Chords, and Rhythmic Patterns\n",
    "for element in score.flat:\n",
    "   if isinstance(element, note.Note):\n",
    "       notes.append([element.offset, element.pitch.midi, element.quarterLength, element.volume.realized])\n",
    "       rhythmic_patterns.append([element.offset, element.quarterLength])\n",
    "   elif isinstance(element, chord.Chord):\n",
    "       chords.append([element.offset] + [p.midi for p in element.pitches])\n",
    "\n",
    "# Extract Tempo\n",
    "for elem in score.flat.getElementsByClass(tempo.MetronomeMark):\n",
    "    tempos.append([elem.offset, elem.number])\n",
    "\n",
    "# Extract Time Signature\n",
    "for elem in score.flat.getElementsByClass(meter.TimeSignature):\n",
    "    time_signatures.append([elem.offset, elem.numerator, elem.denominator])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding for Number of Rows and Columns\n",
    "\n",
    "The resulting arrays of notes, chords, tempos, rhythmic patterns would be of different sizes. This should be padded so that all features have same array length. Sometimes the notes and chords would return Fraction values. These should be coverted and padded accordingly. The below methods are used for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from fractions import Fraction\n",
    "\n",
    "def convert_to_float(value):\n",
    "    if isinstance(value, Fraction):\n",
    "        return float(value)\n",
    "    return float(value)\n",
    "\n",
    "def pad_chord(chord_list, max_notes=4, pad_value=0):\n",
    "    offset = convert_to_float(chord_list[0])\n",
    "    notes = chord_list[1:]\n",
    "    notes = notes + [pad_value] * (max_notes - len(notes))\n",
    "    return [offset] + notes\n",
    "\n",
    "def pad_array(array, max_len, pad_value=0):\n",
    "    padded_array = []\n",
    "    for row in array:\n",
    "        if len(row) < max_len:\n",
    "            row = row + [pad_value] * (max_len - len(row))\n",
    "        padded_array.append(row)\n",
    "    return np.array(padded_array, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method to extract the notes, chords, tempos, rhythmic pattern features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.          48.           1.           0.78740157   0.\n",
      "   49.5         82.          81.          82.           0.\n",
      "    0.          80.           0.           0.           0.\n",
      "    0.           1.           0.           0.           0.\n",
      "    0.           4.           4.           0.           0.        ]\n",
      " [  0.5         72.           0.25         0.78740157   0.\n",
      "  127.5         80.          79.          80.          79.\n",
      "    0.          80.           0.           0.           0.\n",
      "    0.5          0.25         0.           0.           0.\n",
      "    0.           4.           4.           0.           0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from music21 import converter, note, chord, tempo, meter\n",
    "import numpy as np\n",
    "\n",
    "def extract_features(score, max_notes=4):\n",
    "    notes = []\n",
    "    chords = []\n",
    "    tempos = []\n",
    "    rhythmic_patterns = []\n",
    "    time_signatures = []\n",
    "\n",
    "    # Extract Notes, Chords, and Rhythmic Patterns\n",
    "    for element in score.flat:\n",
    "        if isinstance(element, note.Note):\n",
    "            notes.append([\n",
    "                convert_to_float(element.offset),\n",
    "                element.pitch.midi,\n",
    "                convert_to_float(element.quarterLength),\n",
    "                element.volume.realized\n",
    "            ])\n",
    "            rhythmic_patterns.append([\n",
    "                convert_to_float(element.offset),\n",
    "                convert_to_float(element.quarterLength)\n",
    "            ])\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            raw_chord = [\n",
    "                convert_to_float(element.offset)\n",
    "            ] + [p.midi for p in element.pitches]\n",
    "            chords.append(pad_chord(raw_chord, max_notes=max_notes))\n",
    "\n",
    "    # Extract Tempo\n",
    "    for elem in score.flat.getElementsByClass(tempo.MetronomeMark):\n",
    "        tempos.append([\n",
    "            convert_to_float(elem.offset),\n",
    "            elem.number\n",
    "        ])\n",
    "\n",
    "    # Extract Time Signature\n",
    "    for elem in score.flat.getElementsByClass(meter.TimeSignature):\n",
    "        time_signatures.append([\n",
    "            convert_to_float(elem.offset),\n",
    "            elem.numerator,\n",
    "            elem.denominator\n",
    "        ])\n",
    "\n",
    "    # Convert lists to numpy arrays and pad to maximum length\n",
    "    max_len_notes = max((len(row) for row in notes), default=0)\n",
    "    max_len_chords = max((len(row) for row in chords), default=0)\n",
    "    max_len_tempos = max((len(row) for row in tempos), default=0)\n",
    "    max_len_rhythmic_patterns = max((len(row) for row in rhythmic_patterns), default=0)\n",
    "    max_len_time_signatures = max((len(row) for row in time_signatures), default=0)\n",
    "\n",
    "    max_len = max(max_len_notes, max_len_chords, max_len_tempos, max_len_rhythmic_patterns, max_len_time_signatures)\n",
    "\n",
    "    # Pad arrays to ensure they all have the same number of columns\n",
    "    notes_array = pad_array(notes, max_len)\n",
    "    chords_array = pad_array(chords, max_len)\n",
    "    tempos_array = pad_array(tempos, max_len)\n",
    "    rhythmic_patterns_array = pad_array(rhythmic_patterns, max_len)\n",
    "    time_signatures_array = pad_array(time_signatures, max_len)\n",
    "\n",
    "    # Ensure all arrays have the same number of rows\n",
    "    max_rows = min(len(notes_array), len(chords_array), len(tempos_array), len(rhythmic_patterns_array), len(time_signatures_array))\n",
    "    \n",
    "    notes_array = notes_array[:max_rows]\n",
    "    chords_array = chords_array[:max_rows]\n",
    "    tempos_array = tempos_array[:max_rows]\n",
    "    rhythmic_patterns_array = rhythmic_patterns_array[:max_rows]\n",
    "    time_signatures_array = time_signatures_array[:max_rows]\n",
    "\n",
    "    # Ensure that each array has the same number of dimensions\n",
    "    def ensure_2d(array):\n",
    "        if array.ndim == 1:\n",
    "            return array.reshape(-1, 1)\n",
    "        return array\n",
    "\n",
    "    notes_array = ensure_2d(notes_array)\n",
    "    chords_array = ensure_2d(chords_array)\n",
    "    tempos_array = ensure_2d(tempos_array)\n",
    "    rhythmic_patterns_array = ensure_2d(rhythmic_patterns_array)\n",
    "    time_signatures_array = ensure_2d(time_signatures_array)\n",
    "\n",
    "    # Combine features into one array\n",
    "    combined_features = np.hstack((notes_array, chords_array, tempos_array, rhythmic_patterns_array, time_signatures_array))\n",
    "\n",
    "    return combined_features\n",
    "\n",
    "# Example usage for single midi file\n",
    "midi_file = '/Users/manikanr/Downloads/archive/midiclassics/Bach/Bwv0997 Partita for Lute 1mov.mid'  # Replace with your MIDI file path\n",
    "score = converter.parse(midi_file)\n",
    "features = extract_features(score)\n",
    "print(features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to collect Bach composer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collectFeatures(composerName, composerMIDFiles):\n",
    "   features = []\n",
    "   labels = []  # Composer names or folder names\n",
    "   i=1\n",
    "   used_midi_files = []\n",
    "    \n",
    "   for midi_file in composerMIDFiles:\n",
    "       #print(midi_file) \n",
    "       if (i==136): # collect only 136 files\n",
    "          return np.array(features), np.array(labels), np.array(used_midi_files)\n",
    "       try:\n",
    "          score = converter.parse(midi_file)\n",
    "          feature_array = extract_features(score)\n",
    "          features.append(feature_array)\n",
    "          labels.append(composerName)\n",
    "          used_midi_files.append(midi_file)\n",
    "          i=i+1\n",
    "       except Exception as e:\n",
    "          #print(\"Entered Exception for \"+midi_file)\n",
    "          continue \n",
    "  # Assign label based on folder name\n",
    "        \n",
    "   return np.array(features), np.array(labels), np.array(used_midi_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect features and labels for Bach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n",
      "135\n"
     ]
    }
   ],
   "source": [
    "bach_features, bach_labels, bach_used_midi_files = collectFeatures(\"Bach\", bach_midi_files)\n",
    "print(len(bach_features))\n",
    "print(len(bach_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect features and labels for Beethoven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n",
      "135\n"
     ]
    }
   ],
   "source": [
    "beethoven_features, beethoven_labels, beethoven_used_midi_files = collectFeatures(\"Beethoven\", beethoven_midi_files)\n",
    "print(len(beethoven_features))\n",
    "print(len(beethoven_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect features and labels for Chopin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n",
      "135\n"
     ]
    }
   ],
   "source": [
    "chopin_features, chopin_labels, chopin_used_midi_files = collectFeatures(\"Chopin\", chopin_midi_files)\n",
    "print(len(chopin_features))\n",
    "print(len(chopin_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect features and labels for Mozart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n",
      "135\n"
     ]
    }
   ],
   "source": [
    "mozart_features, mozart_labels, mozart_used_midi_files = collectFeatures(\"Mozart\", mozart_midi_files)\n",
    "print(len(mozart_features))\n",
    "print(len(mozart_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation for Convolutional Neural Networks (CNN)\n",
    "\n",
    "Normalize, flatten and re-shape data before applying to CNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def pad_array_3d(array, max_len, pad_value=0.0):\n",
    "    \"\"\" Pad each 2D array in the 3D array to ensure they have consistent shapes. \"\"\"\n",
    "    padded_array = []\n",
    "    max_cols = max(sample.shape[1] for sample in array)  # Find the maximum number of columns\n",
    "\n",
    "    for sample in array:\n",
    "        num_rows, num_cols = sample.shape\n",
    "        # Initialize a new array filled with the pad value, ensuring it has consistent shape\n",
    "        padded_sample = np.full((max_len, max_cols), pad_value)\n",
    "        # Copy the data into the padded array\n",
    "        padded_sample[:num_rows, :num_cols] = sample\n",
    "        padded_array.append(padded_sample)\n",
    "\n",
    "    return np.array(padded_array)\n",
    "\n",
    "\n",
    "# Determine the maximum number of rows in any 2D array (sample)\n",
    "max_len = 0\n",
    "if max(sample.shape[0] for sample in bach_features) > max_len:\n",
    "    max_len = max(sample.shape[0] for sample in bach_features)\n",
    "if max(sample.shape[0] for sample in beethoven_features) > max_len:\n",
    "    max_len = max(sample.shape[0] for sample in beethoven_features)\n",
    "if max(sample.shape[0] for sample in chopin_features) > max_len:\n",
    "    max_len = max(sample.shape[0] for sample in chopin_features)\n",
    "if max(sample.shape[0] for sample in mozart_features) > max_len:\n",
    "    max_len = max(sample.shape[0] for sample in mozart_features)\n",
    "\n",
    "print(max_len)\n",
    "\n",
    "def normalizeFeatures(features, max_len):\n",
    "   # Pad each sample to have the same number of rows\n",
    "   features_padded = pad_array_3d(features, max_len)\n",
    "   # Flatten each 2D array in bach_features_padded to 1D\n",
    "   features_flattened = features_padded.reshape(features_padded.shape[0], -1)\n",
    "\n",
    "   # Apply StandardScaler to the flattened features\n",
    "   scaler = StandardScaler()\n",
    "   features_scaled = scaler.fit_transform(features_flattened)\n",
    "\n",
    "   # If necessary, reshape back to 3D for further processing\n",
    "   features_reshaped = features_scaled.reshape(features_padded.shape)\n",
    "   return features_reshaped\n",
    "\n",
    "#bach_features = scaler.fit_transform(bach_features.reshape(bach_features.shape[0], -1))  # Flatten features if needed\n",
    "#bach_features = bach_features.reshape(bach_features.shape[0], height, width, channels)  # Reshape for CNN\n",
    "\n",
    "# Split data into training and testing sets\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(bach_features_reshaped, bach_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize for all 4 composers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135, 168, 85)\n",
      "(135, 168, 85)\n",
      "(135, 168, 85)\n",
      "(135, 168, 85)\n"
     ]
    }
   ],
   "source": [
    "bach_features_reshaped = normalizeFeatures(bach_features, max_len)\n",
    "beethoven_features_reshaped = normalizeFeatures(beethoven_features, max_len)\n",
    "chopin_features_reshaped = normalizeFeatures(chopin_features, max_len)\n",
    "mozart_features_reshaped = normalizeFeatures(mozart_features, max_len)\n",
    "\n",
    "def pad_to_max_columns(features, max_columns, pad_value=0.0):\n",
    "    \"\"\" Pad the feature arrays to have the same number of columns. \"\"\"\n",
    "    padded_features = []\n",
    "    for sample in features:\n",
    "        num_rows, num_cols = sample.shape\n",
    "        padded_sample = np.full((num_rows, max_columns), pad_value)\n",
    "        padded_sample[:, :num_cols] = sample\n",
    "        padded_features.append(padded_sample)\n",
    "    return np.array(padded_features)\n",
    "\n",
    "# Calculate the maximum number of columns across all datasets\n",
    "max_columns = max(\n",
    "    bach_features_reshaped.shape[2], \n",
    "    beethoven_features_reshaped.shape[2], \n",
    "    chopin_features_reshaped.shape[2], \n",
    "    mozart_features_reshaped.shape[2]\n",
    ")\n",
    "\n",
    "# Pad each feature set to have the same number of columns\n",
    "bach_features_padded = pad_to_max_columns(bach_features_reshaped, max_columns)\n",
    "beethoven_features_padded = pad_to_max_columns(beethoven_features_reshaped, max_columns)\n",
    "chopin_features_padded = pad_to_max_columns(chopin_features_reshaped, max_columns)\n",
    "mozart_features_padded = pad_to_max_columns(mozart_features_reshaped, max_columns)\n",
    "\n",
    "# Print the shapes to verify\n",
    "print(bach_features_padded.shape)\n",
    "print(beethoven_features_padded.shape)\n",
    "print(chopin_features_padded.shape)\n",
    "print(mozart_features_padded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test Split for all 4 composers\n",
    "\n",
    "1. Do the train-test split for each composer separately. This is to create uniformity in training models with CNN.\n",
    "2. Combine each one to get overall train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(432, 168, 85)\n",
      "(108, 168, 85)\n",
      "(432,)\n",
      "(108,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Do the train-test split for each composer separately.\n",
    "bach_x_train, bach_x_test, bach_y_train, bach_y_test = train_test_split(bach_features_padded, bach_labels, test_size=0.2, random_state=42)\n",
    "beethoven_x_train, beethoven_x_test, beethoven_y_train, beethoven_y_test = train_test_split(beethoven_features_padded, beethoven_labels, test_size=0.2, random_state=42)\n",
    "chopin_x_train, chopin_x_test, chopin_y_train, chopin_y_test = train_test_split(chopin_features_padded, chopin_labels, test_size=0.2, random_state=42)\n",
    "mozart_x_train, mozart_x_test, mozart_y_train, mozart_y_test = train_test_split(mozart_features_padded, mozart_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#Combine the train-test split now\n",
    "x_train_combined = np.concatenate(\n",
    "    [bach_x_train, beethoven_x_train, chopin_x_train, mozart_x_train], axis=0\n",
    ")\n",
    "print(x_train_combined.shape)\n",
    "\n",
    "# Concatenate testing features\n",
    "x_test_combined = np.concatenate(\n",
    "    [bach_x_test, beethoven_x_test, chopin_x_test, mozart_x_test], axis=0\n",
    ")\n",
    "print(x_test_combined.shape)\n",
    "\n",
    "# Concatenate training labels\n",
    "y_train_combined = np.concatenate(\n",
    "    [bach_y_train, beethoven_y_train, chopin_y_train, mozart_y_train], axis=0\n",
    ")\n",
    "print(y_train_combined.shape)\n",
    "\n",
    "# Concatenate testing labels\n",
    "y_test_combined = np.concatenate(\n",
    "    [bach_y_test, beethoven_y_test, chopin_y_test, mozart_y_test], axis=0\n",
    ")\n",
    "print(y_test_combined.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding the classes \n",
    "\n",
    "In y to values such as Bach to 0, Beethoven to 1, Chopin to 2 and Mozart to 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(432, 168, 85) (432,)\n",
      "(108, 168, 85) (108,)\n"
     ]
    }
   ],
   "source": [
    "# Define your manual encoding\n",
    "label_mapping = {\n",
    "    \"Bach\": 0,\n",
    "    \"Beethoven\": 1,\n",
    "    \"Chopin\": 2,\n",
    "    \"Mozart\": 3\n",
    "}\n",
    "\n",
    "# Encode the labels\n",
    "y_train_combined_encoded = [label_mapping[label] for label in y_train_combined]\n",
    "y_test_combined_encoded = [label_mapping[label] for label in y_test_combined]\n",
    "\n",
    "# Convert the labels to numpy arrays\n",
    "y_train_combined_encoded = np.array(y_train_combined_encoded)\n",
    "y_test_combined_encoded = np.array(y_test_combined_encoded)\n",
    "\n",
    "# Check shapes to confirm everything is correctly formatted\n",
    "print(x_train_combined.shape, y_train_combined_encoded.shape)\n",
    "print(x_test_combined.shape, y_test_combined_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Design for Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_21 (Conv2D)          (None, 166, 83, 32)       320       \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPooli  (None, 83, 41, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 81, 39, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPooli  (None, 40, 19, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 38, 17, 128)       73856     \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 82688)             0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 64)                5292096   \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5385028 (20.54 MB)\n",
      "Trainable params: 5385028 (20.54 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "num_classes = 4 # Since we have data of 4 composers\n",
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(168, 85, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')  # num_classes = number of output classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training for Convolutional Neural Networks (CNN)\n",
    "\n",
    "Training the CNN model for 10 epochs with training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14/14 [==============================] - 4s 202ms/step - loss: 0.8624 - accuracy: 0.7431 - val_loss: 0.0905 - val_accuracy: 0.9907\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 3s 180ms/step - loss: 0.0512 - accuracy: 0.9861 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 3s 180ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 3s 186ms/step - loss: 4.3778e-04 - accuracy: 1.0000 - val_loss: 3.9657e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 3s 182ms/step - loss: 2.1175e-04 - accuracy: 1.0000 - val_loss: 3.7954e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 3s 184ms/step - loss: 2.3190e-05 - accuracy: 1.0000 - val_loss: 1.3690e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 3s 196ms/step - loss: 1.0371e-05 - accuracy: 1.0000 - val_loss: 1.3042e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 3s 193ms/step - loss: 9.7132e-06 - accuracy: 1.0000 - val_loss: 1.2811e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 3s 182ms/step - loss: 9.4442e-06 - accuracy: 1.0000 - val_loss: 1.2408e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 3s 184ms/step - loss: 9.1244e-06 - accuracy: 1.0000 - val_loss: 1.1985e-05 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_combined, y_train_combined_encoded, epochs=10, batch_size=32, validation_data=(x_test_combined, y_test_combined_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation for Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 59ms/step - loss: 1.1985e-05 - accuracy: 1.0000\n",
      "Test accuracy: 1.0\n",
      "4/4 [==============================] - 0s 43ms/step\n",
      "========================================\n",
      "\n",
      "        Expected Result                   \n",
      "========================================\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "\n",
      "\n",
      "========================================\n",
      "\n",
      "        Actual Result                   \n",
      "========================================\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "\n",
      "\n",
      "========================================\n",
      "\n",
      "   CLASSIFICATION REPORT                \n",
      "\n",
      "========================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        27\n",
      "           1       1.00      1.00      1.00        27\n",
      "           2       1.00      1.00      1.00        27\n",
      "           3       1.00      1.00      1.00        27\n",
      "\n",
      "    accuracy                           1.00       108\n",
      "   macro avg       1.00      1.00      1.00       108\n",
      "weighted avg       1.00      1.00      1.00       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test_combined, y_test_combined_encoded)\n",
    "print(f\"Test accuracy: {test_acc}\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(x_test_combined)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "print(\"========================================\\n\")\n",
    "print(\"        Expected Result                   \")\n",
    "print(\"========================================\\n\")\n",
    "print(y_test_combined_encoded)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"========================================\\n\")\n",
    "print(\"        Actual Result                   \")\n",
    "print(\"========================================\\n\")\n",
    "print(predicted_classes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_test_combined_encoded, predicted_classes)\n",
    "\n",
    "print(\"========================================\\n\")\n",
    "print(\"   CLASSIFICATION REPORT                \\n\")\n",
    "print(\"========================================\\n\")\n",
    "# Print the classification report\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation \n",
    "\n",
    "The report indicates that model has achieved perfect accuracy on the test set, correctly classifying every sample across all four classes. This result suggests that the model performs exceptionally well on this dataset. However, it's also essential to be cautious, as perfect performance may sometimes indicate overfitting, especially if the model's training and validation accuracy were also near perfect. It's a good idea to verify this performance on a separate test set or through cross-validation to ensure the model generalizes well to new, unseen data. This unseen data set testing is done below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with unseen mid files from each of these composers using above CNN model\n",
    "\n",
    "This is to see the model performance on totally unseen data from all 4 music composers using CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Totally Unseen files testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/manikanr/Downloads/archive/midiclassics/Bach/Concertos/Bwv1047 Brandenburg Concert n2 1mov.mid is NOT in bach_used_midi_files.\n",
      "/Users/manikanr/Downloads/archive/midiclassics/Mozart/K299 Flute Harp Concerto 1mov.mid is NOT in bach_used_midi_files.\n",
      "/Users/manikanr/Downloads/archive/midiclassics/Chopin/Piano Concerto n1 op11 1mov.mid is NOT in bach_used_midi_files.\n",
      "/Users/manikanr/Downloads/archive/midiclassics/Beethoven/Bagatella Fur Elise.mid is NOT in bach_used_midi_files.\n",
      "(4, 168, 85)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[2 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bach_new_files = ['/Users/manikanr/Downloads/archive/midiclassics/Bach/Concertos/Bwv1047 Brandenburg Concert n2 1mov.mid',\n",
    "                  '/Users/manikanr/Downloads/archive/midiclassics/Mozart/K299 Flute Harp Concerto 1mov.mid',\n",
    "                  '/Users/manikanr/Downloads/archive/midiclassics/Chopin/Piano Concerto n1 op11 1mov.mid',\n",
    "                  '/Users/manikanr/Downloads/archive/midiclassics/Beethoven/Bagatella Fur Elise.mid']\n",
    "\n",
    "# Check if files in bach_new_files are in already validated files\n",
    "for file in bach_new_files:\n",
    "    if file in bach_used_midi_files:\n",
    "        print(f\"{file} is in bach_used_midi_files.\")\n",
    "    else:\n",
    "        print(f\"{file} is NOT in bach_used_midi_files.\")\n",
    "\n",
    "bach_new_features, bach_new_labels, bach_new_used_files = collectFeatures(\"Bach\", bach_new_files)\n",
    "max_len = max(sample.shape[0] for sample in bach_new_features)\n",
    "bach_new_features_reshaped = normalizeFeatures(bach_new_features, 168)\n",
    "\n",
    "# Pad each feature set to have the same number of columns\n",
    "bach_new_features_padded = pad_to_max_columns(bach_new_features_reshaped, 85)\n",
    "print(bach_new_features_padded.shape)\n",
    "'''\n",
    "# New data shape: (5, 20, 40)\n",
    "bach_new_shape = np.random.rand(5, 20, 40)  # Example data\n",
    "\n",
    "# Expected input shape: (168, 85, 1)\n",
    "expected_shape = (168, 85, 1)\n",
    "\n",
    "# Reshape new data to match expected input shape\n",
    "# This example uses padding with zeros to achieve the desired shape\n",
    "\n",
    "padded_data = np.zeros((5, *expected_shape))  # Initialize with zeros\n",
    "\n",
    "# Insert the original data into the padded array\n",
    "# This assumes you want to place the new data in the top-left corner\n",
    "padded_data[:, :20, :40, 0] = bach_new_shape\n",
    "\n",
    "# Now padded_data should have the shape (5, 168, 85, 1)\n",
    "print(padded_data.shape)  # Should output (5, 168, 85, 1)\n",
    "'''\n",
    "# Make predictions\n",
    "predictions = model.predict(bach_new_features_padded)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "print(predicted_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above without re-training the model on new data, we can say it incorrectly predics few files. After all, our model is not overfit then."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning for CNN\n",
    "\n",
    "Since we got 100% in firly 5 epochs, let's reduce the number of epochs to 5. Also, let's remove two dense hidden layer to see if we can get same performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_26 (Conv2D)          (None, 166, 83, 32)       320       \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPooli  (None, 83, 41, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 108896)            0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 64)                6969408   \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6969988 (26.59 MB)\n",
      "Trainable params: 6969988 (26.59 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "num_classes = 4 # Since we have data of 4 composers\n",
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(168, 85, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')  # num_classes = number of output classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for Performance With 5 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 1.7664 - accuracy: 0.8866 - val_loss: 0.7571 - val_accuracy: 0.9444\n",
      "Epoch 2/5\n",
      "44/44 [==============================] - 3s 59ms/step - loss: 0.1109 - accuracy: 0.9884 - val_loss: 0.8165 - val_accuracy: 0.9352\n",
      "Epoch 3/5\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 0.0288 - accuracy: 0.9954 - val_loss: 0.4006 - val_accuracy: 0.9722\n",
      "Epoch 4/5\n",
      "44/44 [==============================] - 3s 57ms/step - loss: 0.0589 - accuracy: 0.9954 - val_loss: 0.5663 - val_accuracy: 0.9444\n",
      "Epoch 5/5\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 7.3938e-04 - accuracy: 1.0000 - val_loss: 0.5994 - val_accuracy: 0.9444\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_combined, y_train_combined_encoded, epochs=5, batch_size=10, validation_data=(x_test_combined, y_test_combined_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5994 - accuracy: 0.9444\n",
      "Test accuracy: 0.9444444179534912\n",
      "4/4 [==============================] - 0s 22ms/step\n",
      "========================================\n",
      "\n",
      "        Expected Result                   \n",
      "========================================\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "\n",
      "\n",
      "========================================\n",
      "\n",
      "        Actual Result                   \n",
      "========================================\n",
      "\n",
      "[3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 1 1 1 1 1 1 1 2 1\n",
      " 1 1 1 1 1 1 1 1 3 1 1 1 1 1 0 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "\n",
      "\n",
      "========================================\n",
      "\n",
      "   CLASSIFICATION REPORT                \n",
      "\n",
      "========================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94        27\n",
      "           1       1.00      0.85      0.92        27\n",
      "           2       0.93      1.00      0.96        27\n",
      "           3       0.90      1.00      0.95        27\n",
      "\n",
      "    accuracy                           0.94       108\n",
      "   macro avg       0.95      0.94      0.94       108\n",
      "weighted avg       0.95      0.94      0.94       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test_combined, y_test_combined_encoded)\n",
    "print(f\"Test accuracy: {test_acc}\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(x_test_combined)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "print(\"========================================\\n\")\n",
    "print(\"        Expected Result                   \")\n",
    "print(\"========================================\\n\")\n",
    "print(y_test_combined_encoded)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"========================================\\n\")\n",
    "print(\"        Actual Result                   \")\n",
    "print(\"========================================\\n\")\n",
    "print(predicted_classes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_test_combined_encoded, predicted_classes)\n",
    "\n",
    "print(\"========================================\\n\")\n",
    "print(\"   CLASSIFICATION REPORT                \\n\")\n",
    "print(\"========================================\\n\")\n",
    "# Print the classification report\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since removal of 2 dense layers results in reduced performance, lets add one more dense layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-parameter tuning by adding 1 more layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_27 (Conv2D)          (None, 166, 83, 32)       320       \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPooli  (None, 83, 41, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 81, 39, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPooli  (None, 40, 19, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 48640)             0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 64)                3113024   \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3132100 (11.95 MB)\n",
      "Trainable params: 3132100 (11.95 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "num_classes = 4 # Since we have data of 4 composers\n",
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(168, 85, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')  # num_classes = number of output classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Tuned CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "44/44 [==============================] - 4s 69ms/step - loss: 0.3007 - accuracy: 0.8796 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 0.0036 - accuracy: 0.9977 - val_loss: 9.7905e-07 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 9.1807e-07 - accuracy: 1.0000 - val_loss: 8.4881e-07 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 9.3214e-07 - accuracy: 1.0000 - val_loss: 8.4660e-07 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 9.2000e-07 - accuracy: 1.0000 - val_loss: 8.4881e-07 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_combined, y_train_combined_encoded, epochs=5, batch_size=10, validation_data=(x_test_combined, y_test_combined_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 34ms/step - loss: 8.4881e-07 - accuracy: 1.0000\n",
      "Test accuracy: 1.0\n",
      "4/4 [==============================] - 0s 35ms/step\n",
      "========================================\n",
      "\n",
      "        Expected Result                   \n",
      "========================================\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "\n",
      "\n",
      "========================================\n",
      "\n",
      "        Actual Result                   \n",
      "========================================\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "\n",
      "\n",
      "========================================\n",
      "\n",
      "   CLASSIFICATION REPORT                \n",
      "\n",
      "========================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        27\n",
      "           1       1.00      1.00      1.00        27\n",
      "           2       1.00      1.00      1.00        27\n",
      "           3       1.00      1.00      1.00        27\n",
      "\n",
      "    accuracy                           1.00       108\n",
      "   macro avg       1.00      1.00      1.00       108\n",
      "weighted avg       1.00      1.00      1.00       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test_combined, y_test_combined_encoded)\n",
    "print(f\"Test accuracy: {test_acc}\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(x_test_combined)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "print(\"========================================\\n\")\n",
    "print(\"        Expected Result                   \")\n",
    "print(\"========================================\\n\")\n",
    "print(y_test_combined_encoded)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"========================================\\n\")\n",
    "print(\"        Actual Result                   \")\n",
    "print(\"========================================\\n\")\n",
    "print(predicted_classes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_test_combined_encoded, predicted_classes)\n",
    "\n",
    "print(\"========================================\\n\")\n",
    "print(\"   CLASSIFICATION REPORT                \\n\")\n",
    "print(\"========================================\\n\")\n",
    "# Print the classification report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/manikanr/Downloads/archive/midiclassics/Bach/Concertos/Bwv1047 Brandenburg Concert n2 1mov.mid is NOT in bach_used_midi_files.\n",
      "/Users/manikanr/Downloads/archive/midiclassics/Mozart/K299 Flute Harp Concerto 1mov.mid is NOT in bach_used_midi_files.\n",
      "/Users/manikanr/Downloads/archive/midiclassics/Chopin/Piano Concerto n1 op11 1mov.mid is NOT in bach_used_midi_files.\n",
      "/Users/manikanr/Downloads/archive/midiclassics/Beethoven/Bagatella Fur Elise.mid is NOT in bach_used_midi_files.\n",
      "(4, 168, 85)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[2 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bach_new_files = ['/Users/manikanr/Downloads/archive/midiclassics/Bach/Concertos/Bwv1047 Brandenburg Concert n2 1mov.mid',\n",
    "                  '/Users/manikanr/Downloads/archive/midiclassics/Mozart/K299 Flute Harp Concerto 1mov.mid',\n",
    "                  '/Users/manikanr/Downloads/archive/midiclassics/Chopin/Piano Concerto n1 op11 1mov.mid',\n",
    "                  '/Users/manikanr/Downloads/archive/midiclassics/Beethoven/Bagatella Fur Elise.mid']\n",
    "\n",
    "# Check if files in bach_new_files are in already validated files\n",
    "for file in bach_new_files:\n",
    "    if file in bach_used_midi_files:\n",
    "        print(f\"{file} is in bach_used_midi_files.\")\n",
    "    else:\n",
    "        print(f\"{file} is NOT in bach_used_midi_files.\")\n",
    "\n",
    "bach_new_features, bach_new_labels, bach_new_used_files = collectFeatures(\"Bach\", bach_new_files)\n",
    "max_len = max(sample.shape[0] for sample in bach_new_features)\n",
    "bach_new_features_reshaped = normalizeFeatures(bach_new_features, 168)\n",
    "\n",
    "# Pad each feature set to have the same number of columns\n",
    "bach_new_features_padded = pad_to_max_columns(bach_new_features_reshaped, 85)\n",
    "print(bach_new_features_padded.shape)\n",
    "'''\n",
    "# New data shape: (5, 20, 40)\n",
    "bach_new_shape = np.random.rand(5, 20, 40)  # Example data\n",
    "\n",
    "# Expected input shape: (168, 85, 1)\n",
    "expected_shape = (168, 85, 1)\n",
    "\n",
    "# Reshape new data to match expected input shape\n",
    "# This example uses padding with zeros to achieve the desired shape\n",
    "\n",
    "padded_data = np.zeros((5, *expected_shape))  # Initialize with zeros\n",
    "\n",
    "# Insert the original data into the padded array\n",
    "# This assumes you want to place the new data in the top-left corner\n",
    "padded_data[:, :20, :40, 0] = bach_new_shape\n",
    "\n",
    "# Now padded_data should have the shape (5, 168, 85, 1)\n",
    "print(padded_data.shape)  # Should output (5, 168, 85, 1)\n",
    "'''\n",
    "# Make predictions\n",
    "predictions = model.predict(bach_new_features_padded)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "print(predicted_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion and Results for Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has achieved perfect performance on this dataset, with a 100% accuracy, precision, recall, and F1-score across all classes. This is an ideal outcome and suggests that the model has learned to distinguish between the different classes perfectly, at least on the test set provided. However, such perfect scores could sometimes indicate that the model might be overfitting, especially if the dataset is small or not very diverse. But, unseen data provides indifferent results which means more training data set of each of these composers is required. Also, it shows finding differences in music and rhythmic patterns is not an easy task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 168, 128)          109568    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 168, 128)          0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 249668 (975.27 KB)\n",
      "Trainable params: 249668 (975.27 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Define the input shape\n",
    "timesteps = 168  # Number of time steps in the sequence (length of each sequence)\n",
    "input_dim = 85   # Number of features per time step (dimension of each input vector)\n",
    "num_classes = 4  # Number of output classes (e.g., 4 composers)\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(128, input_shape=(timesteps, input_dim), return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(128),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')  # num_classes = number of output classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training to find composers using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "44/44 [==============================] - 9s 110ms/step - loss: 1.0002 - accuracy: 0.4838 - val_loss: 0.8510 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 4s 96ms/step - loss: 0.8514 - accuracy: 0.4931 - val_loss: 0.8342 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 6s 135ms/step - loss: 0.8476 - accuracy: 0.5000 - val_loss: 0.8358 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 5s 105ms/step - loss: 0.8405 - accuracy: 0.5000 - val_loss: 0.8259 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 6s 127ms/step - loss: 0.8284 - accuracy: 0.5093 - val_loss: 0.8337 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 5s 105ms/step - loss: 0.8399 - accuracy: 0.5046 - val_loss: 0.8282 - val_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 5s 112ms/step - loss: 0.8472 - accuracy: 0.4699 - val_loss: 0.8293 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 5s 104ms/step - loss: 0.8414 - accuracy: 0.4861 - val_loss: 0.8334 - val_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 5s 114ms/step - loss: 0.8389 - accuracy: 0.4537 - val_loss: 0.8259 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 5s 107ms/step - loss: 0.8321 - accuracy: 0.4861 - val_loss: 0.8284 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_combined, y_train_combined_encoded, epochs=10, batch_size=10, validation_data=(x_test_combined, y_test_combined_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 125ms/step - loss: 0.8284 - accuracy: 0.5000\n",
      "Test accuracy: 0.5\n",
      "4/4 [==============================] - 1s 103ms/step\n",
      "========================================\n",
      "\n",
      "        Expected Result                   \n",
      "========================================\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "\n",
      "\n",
      "========================================\n",
      "\n",
      "        Actual Result                   \n",
      "========================================\n",
      "\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      "\n",
      "========================================\n",
      "\n",
      "   CLASSIFICATION REPORT                \n",
      "\n",
      "========================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        27\n",
      "           1       1.00      1.00      1.00        27\n",
      "           2       0.33      1.00      0.50        27\n",
      "           3       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.50       108\n",
      "   macro avg       0.33      0.50      0.38       108\n",
      "weighted avg       0.33      0.50      0.38       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test_combined, y_test_combined_encoded)\n",
    "print(f\"Test accuracy: {test_acc}\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(x_test_combined)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "print(\"========================================\\n\")\n",
    "print(\"        Expected Result                   \")\n",
    "print(\"========================================\\n\")\n",
    "print(y_test_combined_encoded)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"========================================\\n\")\n",
    "print(\"        Actual Result                   \")\n",
    "print(\"========================================\\n\")\n",
    "print(predicted_classes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_test_combined_encoded, predicted_classes)\n",
    "\n",
    "print(\"========================================\\n\")\n",
    "print(\"   CLASSIFICATION REPORT                \\n\")\n",
    "print(\"========================================\\n\")\n",
    "# Print the classification report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above, the accuracy, precision, recall and f1-score is poor for composers Bach and Mozart. It only did well for Beethoven here. So, let's do some hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameter tuning for LSTM Model\n",
    "\n",
    "Let's increase number of epochs to 25 for training LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_11 (LSTM)              (None, 168, 128)          109568    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 168, 128)          0         \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 249668 (975.27 KB)\n",
      "Trainable params: 249668 (975.27 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Define the input shape\n",
    "timesteps = 168  # Number of time steps in the sequence (length of each sequence)\n",
    "input_dim = 85   # Number of features per time step (dimension of each input vector)\n",
    "num_classes = 4  # Number of output classes (e.g., 4 composers)\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(128, input_shape=(timesteps, input_dim), return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(128),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')  # num_classes = number of output classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training With Tuned Parameters using LSTM\n",
    "\n",
    "Let's try with 25 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "14/14 [==============================] - 3s 173ms/step - loss: 0.3606 - accuracy: 0.7546 - val_loss: 0.3492 - val_accuracy: 0.7500\n",
      "Epoch 2/25\n",
      "14/14 [==============================] - 2s 172ms/step - loss: 0.3625 - accuracy: 0.7593 - val_loss: 0.3433 - val_accuracy: 0.7500\n",
      "Epoch 3/25\n",
      "14/14 [==============================] - 3s 196ms/step - loss: 0.3540 - accuracy: 0.8079 - val_loss: 0.3085 - val_accuracy: 0.9537\n",
      "Epoch 4/25\n",
      "14/14 [==============================] - 3s 182ms/step - loss: 0.3551 - accuracy: 0.8079 - val_loss: 0.3896 - val_accuracy: 0.7407\n",
      "Epoch 5/25\n",
      "14/14 [==============================] - 4s 270ms/step - loss: 0.3707 - accuracy: 0.7824 - val_loss: 0.2946 - val_accuracy: 0.9074\n",
      "Epoch 6/25\n",
      "14/14 [==============================] - 4s 276ms/step - loss: 0.2604 - accuracy: 0.9444 - val_loss: 0.2231 - val_accuracy: 0.9444\n",
      "Epoch 7/25\n",
      "14/14 [==============================] - 3s 227ms/step - loss: 0.1651 - accuracy: 0.9653 - val_loss: 0.1685 - val_accuracy: 0.9352\n",
      "Epoch 8/25\n",
      "14/14 [==============================] - 3s 184ms/step - loss: 0.1109 - accuracy: 0.9653 - val_loss: 0.3449 - val_accuracy: 0.8241\n",
      "Epoch 9/25\n",
      "14/14 [==============================] - 3s 211ms/step - loss: 0.3603 - accuracy: 0.8565 - val_loss: 0.2883 - val_accuracy: 0.8426\n",
      "Epoch 10/25\n",
      "14/14 [==============================] - 3s 194ms/step - loss: 0.1354 - accuracy: 0.9583 - val_loss: 0.1137 - val_accuracy: 0.9722\n",
      "Epoch 11/25\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.1093 - accuracy: 0.9606 - val_loss: 0.2261 - val_accuracy: 0.8981\n",
      "Epoch 12/25\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.1230 - accuracy: 0.9514 - val_loss: 0.1981 - val_accuracy: 0.8981\n",
      "Epoch 13/25\n",
      "14/14 [==============================] - 4s 289ms/step - loss: 0.0754 - accuracy: 0.9769 - val_loss: 0.0929 - val_accuracy: 0.9815\n",
      "Epoch 14/25\n",
      "14/14 [==============================] - 4s 297ms/step - loss: 0.0590 - accuracy: 0.9815 - val_loss: 0.0983 - val_accuracy: 0.9722\n",
      "Epoch 15/25\n",
      "14/14 [==============================] - 3s 225ms/step - loss: 0.0479 - accuracy: 0.9815 - val_loss: 0.1029 - val_accuracy: 0.9722\n",
      "Epoch 16/25\n",
      "14/14 [==============================] - 3s 234ms/step - loss: 0.0292 - accuracy: 0.9931 - val_loss: 0.0977 - val_accuracy: 0.9815\n",
      "Epoch 17/25\n",
      "14/14 [==============================] - 4s 286ms/step - loss: 0.0281 - accuracy: 0.9884 - val_loss: 0.1034 - val_accuracy: 0.9815\n",
      "Epoch 18/25\n",
      "14/14 [==============================] - 3s 203ms/step - loss: 0.0208 - accuracy: 0.9954 - val_loss: 0.1051 - val_accuracy: 0.9815\n",
      "Epoch 19/25\n",
      "14/14 [==============================] - 2s 153ms/step - loss: 0.0290 - accuracy: 0.9907 - val_loss: 0.1346 - val_accuracy: 0.9722\n",
      "Epoch 20/25\n",
      "14/14 [==============================] - 3s 218ms/step - loss: 0.1539 - accuracy: 0.9398 - val_loss: 0.8201 - val_accuracy: 0.7778\n",
      "Epoch 21/25\n",
      "14/14 [==============================] - 3s 194ms/step - loss: 0.1487 - accuracy: 0.9514 - val_loss: 0.0599 - val_accuracy: 0.9907\n",
      "Epoch 22/25\n",
      "14/14 [==============================] - 3s 191ms/step - loss: 0.0436 - accuracy: 0.9815 - val_loss: 0.0767 - val_accuracy: 0.9815\n",
      "Epoch 23/25\n",
      "14/14 [==============================] - 3s 216ms/step - loss: 0.0310 - accuracy: 0.9884 - val_loss: 0.0727 - val_accuracy: 0.9815\n",
      "Epoch 24/25\n",
      "14/14 [==============================] - 4s 284ms/step - loss: 0.0227 - accuracy: 0.9907 - val_loss: 0.0377 - val_accuracy: 0.9907\n",
      "Epoch 25/25\n",
      "14/14 [==============================] - 5s 352ms/step - loss: 0.0345 - accuracy: 0.9884 - val_loss: 0.0926 - val_accuracy: 0.9907\n"
     ]
    }
   ],
   "source": [
    "# With 25 epochs\n",
    "history = model.fit(x_train_combined, y_train_combined_encoded, epochs=25, batch_size=32, validation_data=(x_test_combined, y_test_combined_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation with tuned LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0926 - accuracy: 0.9907\n",
      "Test accuracy: 0.9907407164573669\n",
      "4/4 [==============================] - 1s 96ms/step\n",
      "========================================\n",
      "\n",
      "        Expected Result                   \n",
      "========================================\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "\n",
      "\n",
      "========================================\n",
      "\n",
      "        Actual Result                   \n",
      "========================================\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 0 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "\n",
      "\n",
      "========================================\n",
      "\n",
      "   CLASSIFICATION REPORT                \n",
      "\n",
      "========================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        27\n",
      "           1       1.00      1.00      1.00        27\n",
      "           2       1.00      1.00      1.00        27\n",
      "           3       1.00      0.96      0.98        27\n",
      "\n",
      "    accuracy                           0.99       108\n",
      "   macro avg       0.99      0.99      0.99       108\n",
      "weighted avg       0.99      0.99      0.99       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test_combined, y_test_combined_encoded)\n",
    "print(f\"Test accuracy: {test_acc}\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(x_test_combined)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "print(\"========================================\\n\")\n",
    "print(\"        Expected Result                   \")\n",
    "print(\"========================================\\n\")\n",
    "print(y_test_combined_encoded)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"========================================\\n\")\n",
    "print(\"        Actual Result                   \")\n",
    "print(\"========================================\\n\")\n",
    "print(predicted_classes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_test_combined_encoded, predicted_classes)\n",
    "\n",
    "print(\"========================================\\n\")\n",
    "print(\"   CLASSIFICATION REPORT                \\n\")\n",
    "print(\"========================================\\n\")\n",
    "# Print the classification report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Totally unseen files Testing using Long Short Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/manikanr/Downloads/archive/midiclassics/Bach/Concertos/Bwv1047 Brandenburg Concert n2 1mov.mid is NOT in bach_used_midi_files.\n",
      "/Users/manikanr/Downloads/archive/midiclassics/Mozart/K299 Flute Harp Concerto 1mov.mid is NOT in bach_used_midi_files.\n",
      "/Users/manikanr/Downloads/archive/midiclassics/Chopin/Piano Concerto n1 op11 1mov.mid is NOT in bach_used_midi_files.\n",
      "/Users/manikanr/Downloads/archive/midiclassics/Beethoven/Bagatella Fur Elise.mid is NOT in bach_used_midi_files.\n",
      "(4, 168, 85)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[0 0 3 0]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bach_new_files = ['/Users/manikanr/Downloads/archive/midiclassics/Bach/Concertos/Bwv1047 Brandenburg Concert n2 1mov.mid',\n",
    "                  '/Users/manikanr/Downloads/archive/midiclassics/Mozart/K299 Flute Harp Concerto 1mov.mid',\n",
    "                  '/Users/manikanr/Downloads/archive/midiclassics/Chopin/Piano Concerto n1 op11 1mov.mid',\n",
    "                  '/Users/manikanr/Downloads/archive/midiclassics/Beethoven/Bagatella Fur Elise.mid']\n",
    "\n",
    "# Check if files in bach_new_files are in already validated files\n",
    "for file in bach_new_files:\n",
    "    if file in bach_used_midi_files:\n",
    "        print(f\"{file} is in bach_used_midi_files.\")\n",
    "    else:\n",
    "        print(f\"{file} is NOT in bach_used_midi_files.\")\n",
    "\n",
    "bach_new_features, bach_new_labels, bach_new_used_files = collectFeatures(\"Bach\", bach_new_files)\n",
    "max_len = max(sample.shape[0] for sample in bach_new_features)\n",
    "bach_new_features_reshaped = normalizeFeatures(bach_new_features, 168)\n",
    "\n",
    "# Pad each feature set to have the same number of columns\n",
    "bach_new_features_padded = pad_to_max_columns(bach_new_features_reshaped, 85)\n",
    "print(bach_new_features_padded.shape)\n",
    "'''\n",
    "# New data shape: (5, 20, 40)\n",
    "bach_new_shape = np.random.rand(5, 20, 40)  # Example data\n",
    "\n",
    "# Expected input shape: (168, 85, 1)\n",
    "expected_shape = (168, 85, 1)\n",
    "\n",
    "# Reshape new data to match expected input shape\n",
    "# This example uses padding with zeros to achieve the desired shape\n",
    "\n",
    "padded_data = np.zeros((5, *expected_shape))  # Initialize with zeros\n",
    "\n",
    "# Insert the original data into the padded array\n",
    "# This assumes you want to place the new data in the top-left corner\n",
    "padded_data[:, :20, :40, 0] = bach_new_shape\n",
    "\n",
    "# Now padded_data should have the shape (5, 168, 85, 1)\n",
    "print(padded_data.shape)  # Should output (5, 168, 85, 1)\n",
    "'''\n",
    "# Make predictions\n",
    "predictions = model.predict(bach_new_features_padded)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "print(predicted_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion and Results of LSTM Model\n",
    "\n",
    "The model has achieved perfect performance on this dataset, with 98% accuracy, precision, recall, and F1-score across all classes. This is an ideal outcome and suggests that the model has learned to distinguish between the different classes perfectly, at least on the test set provided. However, such perfect scores could sometimes indicate that the model might be overfitting, especially if the dataset is small or not very diverse. Since unseen data provides indifferent results, it can prove more training data set of each of these composers is required. Also, it shows finding differences in music and rhythmic patterns is not an easy task and the above analysis are the basics in building the model. It requires more deeper analysis to get perfect results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
